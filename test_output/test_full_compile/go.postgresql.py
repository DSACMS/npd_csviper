#!/usr/bin/env python3
"""
PostgreSQL CSV Import Script - Generated by CSViper

This script imports CSV data into a PostgreSQL database using pre-generated SQL scripts.

Original CSV: test_data.csv
Generated on: 2025-06-23 02:19:48
"""

import os
import sys
import json
import csv
import click
from dotenv import load_dotenv

# ANSI color codes for terminal output
class Colors:
    DARK_RED = '\033[31m'
    RESET = '\033[0m'
    
    @staticmethod
    def dark_red(text):
        """Format text in dark red color"""
        return f"{Colors.DARK_RED}{text}{Colors.RESET}"


def find_post_import_sql_files(script_dir):
    """
    Find and return post-import SQL files in execution order.
    
    Args:
        script_dir (str): Directory containing the script
        
    Returns:
        List[Tuple[int, str]]: List of (order, filepath) tuples sorted by order
    """
    import glob
    
    post_import_dir = os.path.join(script_dir, 'post_import_sql')
    if not os.path.exists(post_import_dir):
        return []
    
    files_with_order = []
    
    # Look for SQL files in subdirectories
    for root, dirs, files in os.walk(post_import_dir):
        for filename in files:
            # First, look for PostgreSQL-specific files
            if filename.endswith('.postgresql.sql'):
                # Extract numeric prefix
                try:
                    order_str = filename.split('_')[0]
                    order = int(order_str)
                    filepath = os.path.join(root, filename)
                    files_with_order.append((order, filepath))
                except (ValueError, IndexError):
                    # Skip files that don't follow the naming convention
                    continue
    
    # If no PostgreSQL-specific files found, look for generic .sql files
    if not files_with_order:
        for root, dirs, files in os.walk(post_import_dir):
            for filename in files:
                if filename.endswith('.sql') and not filename.endswith('.mysql.sql'):
                    # Extract numeric prefix
                    try:
                        order_str = filename.split('_')[0]
                        order = int(order_str)
                        filepath = os.path.join(root, filename)
                        files_with_order.append((order, filepath))
                    except (ValueError, IndexError):
                        # Skip files that don't follow the naming convention
                        continue
    
    # Sort by order
    files_with_order.sort(key=lambda x: x[0])
    
    return files_with_order


def execute_post_import_sql(connection, post_import_files, db_schema_name, table_name):
    """
    Execute post-import SQL files in order.
    
    Args:
        connection: Database connection
        post_import_files (List[Tuple[int, str]]): List of (order, filepath) tuples
        db_schema_name (str): Database schema name
        table_name (str): Table name
    """
    if not post_import_files:
        click.echo("No post-import SQL files found")
        return
    
    click.echo(f"Executing {len(post_import_files)} post-import SQL files...")
    
    with connection.cursor() as cursor:
        for order, filepath in post_import_files:
            filename = os.path.basename(filepath)
            click.echo(f"Executing post-import SQL: {filename}")
            
            # Read SQL file
            with open(filepath, 'r', encoding='utf-8') as f:
                sql_content = f.read()
            
            # Replace placeholders
            sql_content = sql_content.replace('REPLACE_ME_DATABASE_NAME', db_schema_name) \
                                   .replace('REPLACE_ME_TABLE_NAME', table_name)
            
            # Split into individual statements and execute
            statements = [stmt.strip() for stmt in sql_content.split(';') if stmt.strip()]
            for statement in statements:
                if statement and not statement.startswith('--'):
                    try:
                        click.echo(f"  Executing: {statement}")
                        cursor.execute(statement)
                        connection.commit()
                    except Exception as e:
                        click.echo(Colors.dark_red(f"Warning: Error executing statement in {filename}: {e}"))
                        click.echo(Colors.dark_red(f"  Failed statement: {statement}"))
                        # Continue with next statement
                        continue
    
    click.echo("âœ“ Post-import SQL execution completed")


def find_env_file():
    """
    Find .env file in current directory or parent directory.
    
    Returns:
        str: Path to .env file or None if not found
    """
    # Check current directory
    current_dir_env = os.path.join(os.getcwd(), '.env')
    if os.path.exists(current_dir_env):
        return current_dir_env
    
    # Check parent directory
    parent_dir_env = os.path.join(os.path.dirname(os.getcwd()), '.env')
    if os.path.exists(parent_dir_env):
        return parent_dir_env
    
    return None


def check_gitignore_for_env():
    """
    Check if .env is excluded in local .gitignore file.
    Warns if .env is not properly excluded.
    """
    gitignore_path = os.path.join(os.getcwd(), '.gitignore')
    if os.path.exists(gitignore_path):
        with open(gitignore_path, 'r') as f:
            gitignore_content = f.read()
            if '.env' not in gitignore_content:
                click.echo("Warning: .env file should be added to .gitignore to avoid committing credentials")
    else:
        click.echo("Warning: No .gitignore file found. Consider creating one and adding .env to it")


def validate_csv_header(csv_file, expected_columns):
    """
    Validate that CSV header matches expected columns from metadata.
    
    Args:
        csv_file (str): Path to CSV file
        expected_columns (list): Expected column names from metadata
        
    Raises:
        ValueError: If headers don't match
    """
    with open(csv_file, 'r', newline='') as f:
        reader = csv.reader(f)
        actual_header = next(reader)
    
    if len(actual_header) != len(expected_columns):
        raise ValueError(Colors.dark_red(f"Column count mismatch: Expected {len(expected_columns)}, got {len(actual_header)}"))
    
    for i, (expected, actual) in enumerate(zip(expected_columns, actual_header)):
        if expected != actual:
            raise ValueError(Colors.dark_red(f"Column {i+1} mismatch: Expected '{expected}', got '{actual}'"))


def load_sql_file(filename):
    """
    Load SQL content from file.
    
    Args:
        filename (str): SQL filename
        
    Returns:
        str: SQL content
    """
    script_dir = os.path.dirname(os.path.abspath(__file__))
    sql_path = os.path.join(script_dir, filename)
    
    if not os.path.exists(sql_path):
        raise FileNotFoundError(Colors.dark_red(f"SQL file not found: {sql_path}"))
    
    with open(sql_path, 'r') as f:
        return f.read()


def replace_sql_placeholders(sql_content, db_name, table_name, csv_path):
    """
    Replace placeholders in SQL content with actual values.
    
    Args:
        sql_content (str): SQL content with placeholders
        db_name (str): Database/schema name
        table_name (str): Table name
        csv_path (str): Full path to CSV file
        
    Returns:
        str: SQL content with placeholders replaced
    """
    return sql_content.replace('REPLACE_ME_DB_NAME', db_name) \
                     .replace('REPLACE_ME_TABLE_NAME', table_name) \
                     .replace('REPLACE_ME_CSV_FULL_PATH', csv_path)


def execute_postgresql_import(db_config, db_schema_name, table_name, csv_file, trample):
    """
    Execute PostgreSQL import process.
    
    Args:
        db_config (dict): Database configuration
        db_schema_name (str): Database schema name
        table_name (str): Table name
        csv_file (str): Path to CSV file
        trample (bool): Whether to overwrite existing data
    """
    try:
        import psycopg2
        import psycopg2.extras
    except ImportError:
        raise ImportError(Colors.dark_red("psycopg2 library is required for PostgreSQL imports. Install with: pip install psycopg2-binary"))
    
    # Load SQL files
    create_table_sql = load_sql_file('test_data.create_table_postgres.sql')
    
    # Replace placeholders
    csv_full_path = os.path.abspath(csv_file)
    create_table_sql = replace_sql_placeholders(create_table_sql, db_schema_name, table_name, csv_full_path)
    
    # Connect to database
    connection = psycopg2.connect(
        host=db_config['DB_HOST'],
        port=int(db_config['DB_PORT']),
        user=db_config['DB_USER'],
        password=db_config['DB_PASSWORD'],
        database=db_config['DB_NAME']
    )
    
    try:
        with connection.cursor() as cursor:
            # Create schema if it doesn't exist
            cursor.execute(f"CREATE SCHEMA IF NOT EXISTS {db_schema_name}")
            
            # Execute CREATE TABLE statements
            statements = [stmt.strip() for stmt in create_table_sql.split(';') if stmt.strip()]
            for statement in statements:
                if statement:
                    click.echo(f"Executing: {statement}...")
                    cursor.execute(statement)
            
            # Import data using COPY FROM STDIN with progress bar
            click.echo("Importing data...")
            
            # Get file size for progress tracking
            file_size = os.path.getsize(csv_file)
            
            # Build the COPY command
            copy_sql = f"COPY {db_schema_name}.{table_name} FROM STDIN WITH CSV HEADER"
            
            # Create a progress bar wrapper for the file
            class ProgressFileWrapper:
                def __init__(self, file_obj, file_size):
                    self.file_obj = file_obj
                    self.file_size = file_size
                    self.bytes_read = 0
                    self.progress_bar = click.progressbar(length=file_size, 
                                                        label='Uploading CSV data',
                                                        show_percent=True,
                                                        show_eta=True)
                    self.progress_bar.__enter__()
                
                def read(self, size=-1):
                    data = self.file_obj.read(size)
                    if data:
                        self.bytes_read += len(data)
                        self.progress_bar.update(len(data))
                    return data
                
                def readline(self):
                    line = self.file_obj.readline()
                    if line:
                        self.bytes_read += len(line)
                        self.progress_bar.update(len(line))
                    return line
                
                def __getattr__(self, name):
                    return getattr(self.file_obj, name)
                
                def close(self):
                    self.progress_bar.__exit__(None, None, None)
                    self.file_obj.close()
            
            with open(csv_file, 'r') as f:
                progress_wrapper = ProgressFileWrapper(f, file_size)
                try:
                    cursor.copy_expert(copy_sql, progress_wrapper)
                finally:
                    progress_wrapper.close()
            
            # Get row count
            cursor.execute(f"SELECT COUNT(*) FROM {db_schema_name}.{table_name}")
            row_count = cursor.fetchone()[0]
            click.echo(f"âœ“ Successfully imported {row_count:,} rows")
        
        connection.commit()
        
        # Execute post-import SQL files
        script_dir = os.path.dirname(os.path.abspath(__file__))
        post_import_files = find_post_import_sql_files(script_dir)
        execute_post_import_sql(connection, post_import_files, db_schema_name, table_name)
        
    finally:
        connection.close()


@click.command()
@click.option('--env_file_location', type=click.Path(),
              help='Path to .env file (auto-detected if not specified)')
@click.option('--csv_file', required=True, type=click.Path(),
              help='Path to CSV file to import')
@click.option('--db_schema_name', required=False,
              help='Database schema name (can be set via DB_SCHEMA env var)')
@click.option('--table_name', required=False,
              help='Table name for the imported data (can be set via DB_TABLE env var)')
@click.option('--trample', is_flag=True, default=False,
              help='Overwrite existing table data')
def main(env_file_location, csv_file, db_schema_name, table_name, trample):
    """
    Import CSV data into PostgreSQL database using pre-generated SQL scripts.
    
    This script was generated by CSViper for the CSV file: test_data.csv
    """
    try:
        # Expand user path (handle ~ symbol)
        csv_file = os.path.expanduser(csv_file)
        
        # Validate CSV file exists
        if not os.path.exists(csv_file):
            raise FileNotFoundError(Colors.dark_red(f"CSV file not found: {csv_file}"))
        
        # Find .env file
        if env_file_location:
            env_file_location = os.path.expanduser(env_file_location)
            if not os.path.exists(env_file_location):
                raise FileNotFoundError(Colors.dark_red(f".env file not found: {env_file_location}"))
            env_file = env_file_location
        else:
            env_file = find_env_file()
            if not env_file:
                raise FileNotFoundError(Colors.dark_red("No .env file found. Specify --env_file_location or place .env in current/parent directory"))
        
        # Check .gitignore
        check_gitignore_for_env()
        
        # Load environment variables
        load_dotenv(env_file)
        
        # Get database configuration
        required_vars = ['DB_HOST', 'DB_PORT', 'DB_USER', 'DB_PASSWORD', 'DB_NAME']
        optional_vars = ['DB_SCHEMA', 'DB_TABLE', 'DEBUG', 'SECRET_KEY']
        db_config = {}
        
        for var in required_vars:
            value = os.getenv(var)
            if not value:
                raise ValueError(Colors.dark_red(f"Required environment variable not found: {var}"))
            db_config[var] = value
        
        for var in optional_vars:
            value = os.getenv(var)
            if value:
                db_config[var] = value
        
        # Load metadata to validate CSV header
        script_dir = os.path.dirname(os.path.abspath(__file__))
        metadata_file = os.path.join(script_dir, 'test_data.metadata.json')
        
        with open(metadata_file, 'r') as f:
            metadata = json.load(f)
        
        # Determine schema and table names
        if not db_schema_name:
            db_schema_name = db_config.get('DB_SCHEMA')
            if not db_schema_name:
                raise ValueError(Colors.dark_red("Database schema name must be provided via --db_schema_name or DB_SCHEMA environment variable"))
        
        if not table_name:
            table_name = db_config.get('DB_TABLE')
            if not table_name:
                raise ValueError(Colors.dark_red("Table name must be provided via --table_name or DB_TABLE environment variable"))
        
        # Validate CSV header
        expected_columns = metadata['original_column_names']
        validate_csv_header(csv_file, expected_columns)
        
        # Check debug mode
        debug_mode = db_config.get('DEBUG', '').lower() in ('true', '1', 'yes', 'on')
        if debug_mode:
            click.echo("Debug mode enabled")
        
        click.echo(f"Importing {os.path.basename(csv_file)} into PostgreSQL database")
        click.echo(f"Schema: {db_schema_name}, Table: {table_name}")
        
        if trample:
            click.echo("Warning: --trample flag is set. Existing table data will be overwritten.")
        
        # Execute PostgreSQL import
        execute_postgresql_import(db_config, db_schema_name, table_name, csv_file, trample)
        
        click.echo("âœ“ PostgreSQL import completed successfully!")
        
    except Exception as e:
        click.echo(Colors.dark_red(f"Error: {e}"), err=True)
        sys.exit(1)


if __name__ == '__main__':
    main()
